# Awesome-Multi-Modal Object Re-Identification Repository

Welcome to the Awesome-Multi-Modal Object Re-Identification Repository! This repository is dedicated to curating and sharing cutting-edge methods and resources specifically focused on multi-modal object re-identification.

## My Papers
- [CVPR24-EDITOR]<br>*Magic Tokens: Select Diverse Tokens for Multi-modal Object Re-Identification*<br>[Paper](<https://arxiv.org/abs/2403.10254>) [Code](<https://github.com/924973292/EDITOR>)
- [AAAI24-TOP-ReID]<br>*TOP-ReID: Multi-spectral Object Re-Identification with Token Permutation*<br>[Paper](<https://arxiv.org/abs/2312.09612>) [Code](<https://github.com/924973292/TOP-ReID>)

## Multi-Modal ReID

### Methods

#### Multi-Modal Person ReID
- [CVPR2024-AIO]<br>*All in One Framework for Multimodal Re-identification in the Wild*<br>[Paper](<https://arxiv.org/pdf/2405.04741>) [Code](<https://github.com/lihe404/AIO>)
- [MLCCIM23-MMCF]<br>*Multimodal Consistency Co-Assisted Training for Person Re-Identification*<br>[Paper](<https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10339497>)
- [ICSP23-LRFNet]<br>*Low-rank Fusion Network for Multi-modality Person Re-identification*<br>[Paper](<https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10248672>)
- [TNNLS23-DENet]<br>*Dynamic Enhancement Network for Partial Multi-modality Person Re-identification*<br>[Paper](https://arxiv.org/abs/2305.15762)
- [AAAI22-IEEE]<br>*Interact, Embed, and EnlargE: Boosting Modality-Specific Representations for Multi-Modal Person Re-identification*<br>[Paper](<https://ojs.aaai.org/index.php/AAAI/article/view/20165>) [Code](<https://github.com/littleprince1121/IEEE_Boosting_Modality-specific_Representations_for_Multi-Modal_Person_ReID>)
- [AAAI21-PFNet]<br>*Robust Multi-Modality Person Re-identification*<br>[Paper](<https://ojs.aaai.org/index.php/AAAI/article/view/16467>)

#### Multi-Modal Vehicle ReID
- [Sensors23-PHT]<br>*Progressively Hybrid Transformer for Multi-Modal Vehicle Re-Identification*<br>[Paper](<https://www.mdpi.com/1424-8220/23/9/4206>)
- [TITS23-GPFNet]<br>*Graph-based progressive fusion network for multi-modality vehicle re-identification*<br>[Paper](<https://ieeexplore.ieee.org/document/10159551>)
- [Inform Fusion22-CCNet]<br>*Multi-spectral Vehicle Re-identification with Cross-directional Consistency Network and A High-quality Benchmark*<br>[Paper](<https://arxiv.org/abs/2208.00632>) [Code](<https://github.com/superlollipop123/Cross-directional-Center-Network-and-MSVR310>)
- [ICSP22-GAFNet]<br>*Generative and attentive fusion for multi-spectral vehicle re-identification*<br>[Paper](<https://ieeexplore.ieee.org/document/9778769?denied=>)
- [AAAI20-HAMNet]<br>*Multi-Spectral Vehicle Re-Identification: A Challenge*<br>[Paper](<https://ojs.aaai.org/index.php/AAAI/article/view/6796>) [Code](<https://github.com/ttaalle/multi-modal-vehicle-Re-ID>)

#### Multi-Modal Object ReID
- [Sensors24-MambaReID]<br>*MambaReID: Exploiting Vision Mamba for Multi-Modal Object Re-Identification*<br>[Paper](<https://www.mdpi.com/1424-8220/24/14/4639>)
- [CVPR24-EDITOR]<br>*Magic Tokens: Select Diverse Tokens for Multi-modal Object Re-Identification*<br>[Paper](<https://arxiv.org/abs/2403.10254>) [Code](<https://github.com/924973292/EDITOR>)
- [AAAI24-TOP-ReID]<br>*TOP-ReID: Multi-spectral Object Re-Identification with Token Permutation*<br>[Paper](<https://arxiv.org/abs/2312.09612>) [Code](<https://github.com/924973292/TOP-ReID>)
- [AAAI24-HTT]<br>*Heterogeneous Test-Time Training for Multi-Modal Person Re-identifcation*<br>[Paper](<https://ojs.aaai.org/index.php/AAAI/article/view/28398>) [Code](<https://github.com/ziwang1121/HTT>)
- [NeurIPS23-UniCat]<br>*UniCat: Crafting a Stronger Fusion Baseline for Multimodal Re-Identification*<br>[Paper](<https://arxiv.org/pdf/2310.18812.pdf>) [Code](<https://github.com/Nano1337/UniCat>)
- [arXiv23-GraFT]<br>*GraFT: Gradual Fusion Transformer for Multimodal Re-Identification*<br>[Paper](<https://arxiv.org/pdf/2310.16856v1.pdf>) [Code](<https://github.com/Nano1337/GraFT>)

### Datasets
#### Multi-Modal Person ReID
- [RGBNT201(RGB+NIR+TIR)](<https://drive.google.com/drive/folders/1EscBadX-wMAT56_It5lXY-S3-b5nK1wH>)
- [Market1501-MM(RGB+NIR+TIR)](<https://drive.google.com/drive/folders/1EscBadX-wMAT56_It5lXY-S3-b5nK1wH>)
#### Multi-Modal Vehicle ReID
- [RGBNT100(RGB+NIR+TIR)](<https://pan.baidu.com/s/1xqqh7N4Lctm3RcUdskG0Ug>) (rjin) 
- [RGBNT300(RGB+NIR)](https://pan.baidu.com/s/1xqqh7N4Lctm3RcUdskG0Ug) (rjin)
- [MSVR310(RGB+NIR+TIR)](https://drive.google.com/file/d/1IxI-fGiluPO_Ies6YjDHeTEuVYhFdYwD/view?usp=drive_link)
- [MSVWild863(RGB+NIR+TIR)](https://github.com/Mzq12138/Official-Implementation-for-Flare-Aware-Cross-modal-Enhancement-for-Multi-spectral-Vehicle-ReID?tab=readme-ov-file) (msvw)

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=924973292/Awesome-Multi-Modal-Object-Re-Identification&type=Date)](https://star-history.com/#924973292/Awesome-Multi-Modal-Object-Re-Identification&Date)

## Acknowledgments

I want to express my gratitude to the academic community and everyone contributing to the advancement of multi-modal object re-identification research.

## Contact

Feel free to reach out if you have any questions, suggestions, or collaboration proposals:

- Email: [924973292@mail.dlut.edu.cn](mailto:924973292@mail.dlut.edu.cn)
- Web: [924973292.github.io](https://924973292.github.io//)


## Citation
If you find our work useful in your research, please consider citing our papers:
```bibtex
@inproceedings{wang2024top,
  title={TOP-ReID: Multi-spectral Object Re-Identification with Token Permutation},
  author={Wang, Yuhao and Liu, Xuehu and Zhang, Pingping and Lu, Hu and Tu, Zhengzheng and Lu, Huchuan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={6},
  pages={5758--5766},
  year={2024}
}

@InProceedings{Zhang_2024_CVPR,
    author    = {Zhang, Pingping and Wang, Yuhao and Liu, Yang and Tu, Zhengzheng and Lu, Huchuan},
    title     = {Magic Tokens: Select Diverse Tokens for Multi-modal Object Re-Identification},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2024},
    pages     = {17117-17126}
}
```