# Awesome-Multi-Modal Object Re-Identification Repository

Welcome to the Awesome-Multi-Modal Object Re-Identification Repository! This repository is dedicated to curating and sharing cutting-edge methods and resources specifically focused on multi-modal object re-identification.

## My Papers
- [CVPR25-IDEA]<br>*IDEA: Inverted Text with Cooperative Deformable Aggregation for Multi-modal Object Re-Identification*<br>[Paper](https://arxiv.org/pdf/2503.10324) [Code](<https://github.com/924973292/IDEA>)
- [AAAI25-DeMo]<br>*DeMo: Decoupled Feature-Based Mixture of Experts for Multi-Modal Object Re-Identification*<br>[Paper](https://arxiv.org/pdf/2412.10650) [Code](<https://github.com/924973292/DeMo>)
- [AAAI25-MambaPro]<br>*MambaPro: Multi-Modal Object Re-identification with Mamba Aggregation and Synergistic Prompt*<br>[Paper](https://arxiv.org/pdf/2412.10707) [Code](<https://github.com/924973292/MambaPro>)
- [CVPR24-EDITOR]<br>*Magic Tokens: Select Diverse Tokens for Multi-modal Object Re-Identification*<br>[Paper](<https://arxiv.org/abs/2403.10254>) [Code](<https://github.com/924973292/EDITOR>)
- [AAAI24-TOP-ReID]<br>*TOP-ReID: Multi-spectral Object Re-Identification with Token Permutation*<br>[Paper](<https://arxiv.org/abs/2312.09612>) [Code](<https://github.com/924973292/TOP-ReID>)

## Multi-Modal ReID

### Methods

#### Multi-Modal Object ReID
- [TIP25-DESANet]<br>*Escaping Modal Interactions: An Efficient DESANet for Multi-Modal Object Re-identification*<br>[Paper](https://ieeexplore.ieee.org/abstract/document/11104996) [Code](https://github.com/DWJ11/DESANet)
- [CSCWD25-LMCNet]<br>*Lightweight Multi-Branch Feature Complementary Network for Multi-Modal Object Re-Identification*<br>[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11033597)
- [ArXiv25-UGG-ReID]<br>*UGG-ReID: Uncertainty-Guided Graph Model for Multi-Modal Object Re-Identification*<br>[Paper](https://arxiv.org/pdf/2507.04638)
- [ICML25-MFRNet]<br>*Multi-Modal Object Re-Identification via Sparse Mixture-of-Experts*<br>[Paper](https://openreview.net/pdf?id=uvFE58mSnR) [Code](https://github.com/stone96123/MFRNet)
- [ArXiv25-NEXT]<br>*NEXT: Multi-Grained Mixture of Experts via Text-Modulation for Multi-Modal Object Re-ID*<br>[Paper](https://arxiv.org/pdf/2505.20001)
- [TMM25-ICPL]<br>*ICPL-ReID: Identity-Conditional Prompt Learning for Multi-Spectral Object Re-Identification*<br>[Paper](https://arxiv.org/pdf/2505.17821) [Code](https://github.com/lsh-ahu/ICPL-ReID)
- [ArXiv25-MGRNet]<br>*Reliable Multi-Modal Object Re-Identification via Modality-Aware Graph Reasoning*<br>[Paper](https://arxiv.org/pdf/2504.14847)
- [WACV25-DMPT]<br>*DMPT: Decoupled Modality-Aware Prompt Tuning for Multi-Modal Object Re-Identification*<br>[Paper](https://ieeexplore.ieee.org/abstract/document/10944073)
- [TIP25-PromptMA]<br>*Prompt-Based Modality Alignment for Effective Multi-Modal Object Re-Identification*<br>[Paper](https://ieeexplore.ieee.org/abstract/document/10955143) [Code](<https://github.com/FHR-L/PromptMA>)
- [CVPR25-IDEA]<br>*IDEA: Inverted Text with Cooperative Deformable Aggregation for Multi-modal Object Re-Identification*<br>[Paper](https://arxiv.org/pdf/2503.10324) [Code](<https://github.com/924973292/IDEA>)
- [ArXiv25]<br>*Modality Unified Attack for Omni-Modality Person Re-Identification*<br>[Paper](https://arxiv.org/pdf/2501.12761)
- [AAAI25-DeMo]<br>*DeMo: Decoupled Feature-Based Mixture of Experts for Multi-Modal Object Re-Identification*<br>[Paper](https://arxiv.org/pdf/2412.10650) [Code](<https://github.com/924973292/DeMo>)
- [AAAI25-MambaPro]<br>*MambaPro: Multi-Modal Object Re-identification with Mamba Aggregation and Synergistic Prompt*<br>[Paper](https://arxiv.org/pdf/2412.10707) [Code](<https://github.com/924973292/MambaPro>)
- [TCSVT24-RSCNet]<br>*Representation Selective Coupling via Token Sparsification for Multi-Spectral Object Re-Identification*<br>[Paper](<https://ieeexplore.ieee.org/abstract/document/10772090>)
- [ESWA25-LRMM]<br>*LRMM: Low rank multi-scale multi-modal fusion for person re-identification based on RGB-NI-TI*<br>[Paper](<https://www.sciencedirect.com/science/article/pii/S0957417424025831>)
- [Sensors24-MambaReID]<br>*MambaReID: Exploiting Vision Mamba for Multi-Modal Object Re-Identification*<br>[Paper](<https://www.mdpi.com/1424-8220/24/14/4639>)
- [CVPR24-EDITOR]<br>*Magic Tokens: Select Diverse Tokens for Multi-modal Object Re-Identification*<br>[Paper](<https://arxiv.org/abs/2403.10254>) [Code](<https://github.com/924973292/EDITOR>)
- [AAAI24-TOP-ReID]<br>*TOP-ReID: Multi-spectral Object Re-Identification with Token Permutation*<br>[Paper](<https://arxiv.org/abs/2312.09612>) [Code](<https://github.com/924973292/TOP-ReID>)
- [AAAI24-HTT]<br>*Heterogeneous Test-Time Training for Multi-Modal Person Re-identifcation*<br>[Paper](<https://ojs.aaai.org/index.php/AAAI/article/view/28398>) [Code](<https://github.com/ziwang1121/HTT>)
- [NeurIPS23-UniCat]<br>*UniCat: Crafting a Stronger Fusion Baseline for Multimodal Re-Identification*<br>[Paper](<https://arxiv.org/pdf/2310.18812.pdf>) [Code](<https://github.com/Nano1337/UniCat>)
- [arXiv23-GraFT]<br>*GraFT: Gradual Fusion Transformer for Multimodal Re-Identification*<br>[Paper](<https://arxiv.org/pdf/2310.16856v1.pdf>) [Code](<https://github.com/Nano1337/GraFT>)

#### Multi-Modal Person ReID
- [TNNLS25-TIENet]<br>*TIENet: A Tri-Interaction Enhancement Network for Multimodal Person Reidentification*<br>[Paper](<https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10934016>)
- [MLCCIM23-MMCF]<br>*Multimodal Consistency Co-Assisted Training for Person Re-Identification*<br>[Paper](<https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10339497>)
- [ICSP23-LRFNet]<br>*Low-rank Fusion Network for Multi-modality Person Re-identification*<br>[Paper](<https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10248672>)
- [TNNLS23-DENet]<br>*Dynamic Enhancement Network for Partial Multi-modality Person Re-identification*<br>[Paper](https://arxiv.org/abs/2305.15762)
- [AAAI22-IEEE]<br>*Interact, Embed, and EnlargE: Boosting Modality-Specific Representations for Multi-Modal Person Re-identification*<br>[Paper](<https://ojs.aaai.org/index.php/AAAI/article/view/20165>) [Code](<https://github.com/littleprince1121/IEEE_Boosting_Modality-specific_Representations_for_Multi-Modal_Person_ReID>)
- [AAAI21-PFNet]<br>*Robust Multi-Modality Person Re-identification*<br>[Paper](<https://ojs.aaai.org/index.php/AAAI/article/view/16467>)


#### Multi-Modal Vehicle ReID
- [IEEE Access25-SV2SAFA-V1]<br>*Swin Transformer With Late-Fusion Feature Aggregation for Multi-Modal Vehicle Reidentification*<br>[Paper](https://ieeexplore.ieee.org/abstract/document/11087485)
- [ArXiv25-CoEN]<br>*Collaborative Enhancement Network for Low-quality Multi-spectral Vehicle Re-identification*<br>[Paper](https://arxiv.org/pdf/2504.14877) [Code](https://github.com/yongqisun/CoEN)
- [Applied Intelligence25]<br>*Generalizable Multi-spectral Vehicle Re-identification via Decoupled Subspaces*<br>[Paper](<https://link.springer.com/chapter/10.1007/978-981-96-1904-7_2>)
- [ESWA25-WTSF-ReID]<br>*Depth-driven Window-oriented Token Selection and Fusion for multi-modality vehicle re-identification with knowledge consistency constraint*<br>[Paper](<https://www.sciencedirect.com/science/article/pii/S0957417425005433?via=ihub>) [Code](<https://github.com/unicofu/WTSF-ReID>)
- [Inform Fusion24-FACENet]<br>*Flare-aware cross-modal enhancement network for multi-spectral vehicle Re-identification*<br>[Paper](<https://www.sciencedirect.com/science/article/pii/S1566253524005785>) [Code](<https://github.com/Mzq12138/Official-Implementation-for-Flare-Aware-Cross-modal-Enhancement-for-Multi-spectral-Vehicle-ReID?tab=readme-ov-file>)
- [Sensors23-PHT]<br>*Progressively Hybrid Transformer for Multi-Modal Vehicle Re-Identification*<br>[Paper](<https://www.mdpi.com/1424-8220/23/9/4206>)
- [TITS23-GPFNet]<br>*Graph-based progressive fusion network for multi-modality vehicle re-identification*<br>[Paper](<https://ieeexplore.ieee.org/document/10159551>)
- [Inform Fusion22-CCNet]<br>*Multi-spectral Vehicle Re-identification with Cross-directional Consistency Network and A High-quality Benchmark*<br>[Paper](<https://arxiv.org/abs/2208.00632>) [Code](<https://github.com/superlollipop123/Cross-directional-Center-Network-and-MSVR310>)
- [ICSP22-GAFNet]<br>*Generative and attentive fusion for multi-spectral vehicle re-identification*<br>[Paper](<https://ieeexplore.ieee.org/document/9778769?denied=>)
- [AAAI20-HAMNet]<br>*Multi-Spectral Vehicle Re-Identification: A Challenge*<br>[Paper](<https://ojs.aaai.org/index.php/AAAI/article/view/6796>) [Code](<https://github.com/ttaalle/multi-modal-vehicle-Re-ID>)

### Datasets
#### Multi-Modal Person ReID
- [RGBNT201(RGB+NIR+TIR)](<https://drive.google.com/drive/folders/1EscBadX-wMAT56_It5lXY-S3-b5nK1wH>)
- [Market1501-MM(RGB+NIR+TIR)](<https://drive.google.com/drive/folders/1EscBadX-wMAT56_It5lXY-S3-b5nK1wH>)
#### Multi-Modal Vehicle ReID
- [RGBNT100(RGB+NIR+TIR)](<https://pan.baidu.com/s/1xqqh7N4Lctm3RcUdskG0Ug>) (rjin) 
- [RGBNT300(RGB+NIR)](https://pan.baidu.com/s/1uiKcqiqdhd13nLSW8TUASg) (11y8)
- [MSVR310(RGB+NIR+TIR)](https://drive.google.com/file/d/1IxI-fGiluPO_Ies6YjDHeTEuVYhFdYwD/view?usp=drive_link)
- [MSVWild863(RGB+NIR+TIR)](https://github.com/Mzq12138/Official-Implementation-for-Flare-Aware-Cross-modal-Enhancement-for-Multi-spectral-Vehicle-ReID?tab=readme-ov-file) (msvw)

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=924973292/Awesome-Multi-Modal-Object-Re-Identification&type=Date)](https://star-history.com/#924973292/Awesome-Multi-Modal-Object-Re-Identification&Date)

## Acknowledgments

I want to express my gratitude to the academic community and everyone contributing to the advancement of multi-modal object re-identification research.

## Contact

Feel free to reach out if you have any questions, suggestions, or collaboration proposals:

- Email: [924973292@mail.dlut.edu.cn](mailto:924973292@mail.dlut.edu.cn)
- Web: [924973292.github.io](https://924973292.github.io//)



## Citation
If you find our work useful in your research, please consider citing our papers:
```bibtex
@inproceedings{wang2024top,
  title={TOP-ReID: Multi-spectral Object Re-Identification with Token Permutation},
  author={Wang, Yuhao and Liu, Xuehu and Zhang, Pingping and Lu, Hu and Tu, Zhengzheng and Lu, Huchuan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={6},
  pages={5758--5766},
  year={2024}
}

@InProceedings{Zhang_2024_CVPR,
    author    = {Zhang, Pingping and Wang, Yuhao and Liu, Yang and Tu, Zhengzheng and Lu, Huchuan},
    title     = {Magic Tokens: Select Diverse Tokens for Multi-modal Object Re-Identification},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2024},
    pages     = {17117-17126}
}

@inproceedings{wang2025decoupled,
  title={Decoupled feature-based mixture of experts for multi-modal object re-identification},
  author={Wang, Yuhao and Liu, Yang and Zheng, Aihua and Zhang, Pingping},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={39},
  number={8},
  pages={8141--8149},
  year={2025}
}

@inproceedings{wang2025mambapro,
  title={Mambapro: Multi-modal object re-identification with mamba aggregation and synergistic prompt},
  author={Wang, Yuhao and Liu, Xuehu and Yan, Tianyu and Liu, Yang and Zheng, Aihua and Zhang, Pingping and Lu, Huchuan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={39},
  number={8},
  pages={8150--8158},
  year={2025}
}

@article{wang2025idea,
  title={IDEA: Inverted Text with Cooperative Deformable Aggregation for Multi-modal Object Re-Identification},
  author={Wang, Yuhao and Lv, Yongfeng and Zhang, Pingping and Lu, Huchuan},
  journal={arXiv preprint arXiv:2503.10324},
  year={2025}
}
```
